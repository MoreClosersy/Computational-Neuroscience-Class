{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_fashion_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Convolutional%20Neural%20Network/cnn_fashion_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "OlZTTlQNgo2o"
      },
      "cell_type": "markdown",
      "source": [
        "# **Convolutional neural network (CNN) for Fashion MNIST dataset**\n",
        "\n",
        "\n",
        "by Md Nasir Uddin Laskar; \n",
        "Edited 2022: Odelia Schwartz and Xu Pan\n",
        "\n",
        "Change colab runtime type to GPU to accelerate: \"Runtime\" --> \"Change runtime type\"--> under \"Hardware accelerator\" select \"GPU\".\n",
        "\n",
        "\n",
        "-  We will implement a simple CNN model with 2 convolution and 2 fully connected layers as the following figure. **conv1 --> relu1 --> pool1 ----> conv2 --> relu2 --> pool2 ----> fc1 --> fc2**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![picture](https://nasirml.files.wordpress.com/2019/01/simple_convnet-3.png?w=580&h=182)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## **Common deep learning steps**\n",
        "\n",
        "* Step 1: Generate training and test data (and preprocess)\n",
        "* Step 2: Initialize the network parameters\n",
        "* Step 3: Forward propagation\n",
        "* Step 4: Compute the cost/loss\n",
        "* Step 5: Backpropagation or create an optimizer to minimize the cost from step 4\n",
        "* Step 6: Evaluate the model with your test set\n"
      ]
    },
    {
      "metadata": {
        "id": "SXQ-_3sPglUf"
      },
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import os   # to save the checkpoint\n",
        "#sess = tf.InteractiveSession()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ac8hAAEKtoWN"
      },
      "cell_type": "markdown",
      "source": [
        "# **Load the dataset**\n",
        "* **Fashion-MNIST** is a dataset of article images—consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. It shares the same image size and structure of training and testing splits of MNIST.\n",
        "\n",
        "\n",
        "* The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The labels are an array of integers, ranging from 0 to 9. These correspond to the class of clothing the image represents.\n",
        "\n",
        "* MNIST is very easy. Classic machine learning algorithms can also achieve 97% easily as you have see in the last lab. With convolutional nets, we can achieve 99.7% on MNIST. That is why we are trying a more serious dataset which a bit challenging but still gives us the fexibility and ease of MNIST.\n",
        "\n",
        "* Sample images from the Fashion MNIST data in the following figure (each class takes three rows).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Hqi0oCa4RLO-"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\"  width=\"600\">\n",
        "  </td></tr>\n",
        "  <tr><td align=\"center\">\n",
        "    <b>Figure 1.</b> <a href=\"https://github.com/zalandoresearch/fashion-mnist\">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;\n",
        "  </td></tr>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "JJcWxazVBbGA"
      },
      "cell_type": "markdown",
      "source": [
        "Loading the dataset returns four NumPy arrays:\n",
        "\n",
        "* The `x_train` and `y_train` arrays are the *training set*—the data the model uses to learn.\n",
        "* The model is tested against the *test set*, the `x_test`, and `y_test` arrays.\n",
        "\n",
        "The images are 28x28 NumPy arrays, with pixel values ranging between 0 and 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td> \n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td> \n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td> \n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "* Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:\n",
        "\n",
        "* **loading the dataset is very easy as it is already included in the TensorFlow/Keras library. We just have to include `tf.keras.datasets.fashion_mnist` and call the `load_data()` function.**\n",
        "* It returns training and test datasets including the labels. \n"
      ]
    },
    {
      "metadata": {
        "id": "bypNXqd5g_CS"
      },
      "cell_type": "code",
      "source": [
        "def read_dataset():\n",
        "  '''\n",
        "  - read fashion mnist dataset\n",
        "  - \n",
        "  '''\n",
        "  fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "  (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "  \n",
        "  return x_train, y_train, x_test, y_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wy-kGdjSiye2"
      },
      "cell_type": "code",
      "source": [
        "# call the function to read fashion mnist\n",
        "x_train, y_train, x_test, y_test = read_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r25Dn4Pdj-3T"
      },
      "cell_type": "markdown",
      "source": [
        "# **Look at the data**\n",
        "\n",
        "* **Training data** — used for training the model.\n",
        "\n",
        "* **Test data** — are the images not seen the network yet. A totally new set to test the generalization capability of the network. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Nf2rKSqQx1Sl"
      },
      "cell_type": "code",
      "source": [
        "print('Training data size:' + str(x_train.shape))\n",
        "print('Training labels size: ' + str(y_train.shape))\n",
        "\n",
        "print('Test data size: ' + str(x_test.shape))\n",
        "print('Test label size: ' + str(y_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cPZhF5SZkVFE"
      },
      "cell_type": "code",
      "source": [
        "fashion_mnist_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "                        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "print(fashion_mnist_labels)\n",
        "print(y_train[100], fashion_mnist_labels[y_train[100]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C0VT02lFkFgM"
      },
      "cell_type": "code",
      "source": [
        "# look at the first 10 images\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i+1); plt.axis('off')\n",
        "    plt.imshow(np.reshape(x_train[i], [28, 28]), cmap='gray')\n",
        "    plt.title(fashion_mnist_labels[y_train[i]])    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hB7-TVbmzMIy"
      },
      "cell_type": "markdown",
      "source": [
        "# **Preprocess data**\n",
        "* **One-hot encoding.** \n",
        "* Reshape to `28 x 28x 1`\n"
      ]
    },
    {
      "metadata": {
        "id": "WuR0FxO07mIu"
      },
      "cell_type": "code",
      "source": [
        "# normalize the images\n",
        "#x_train = x_train.astype('float32')/255.0  # sometimes standard to have pixel values in the range [0,1]\n",
        "#x_test = x_test.astype('float32')/255.0 \n",
        "\n",
        "# Convert the labels to one-hot vectors\n",
        "print(y_train[0:5])\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)  # 10 classes\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "print(y_train[0:5])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4IaX8lgRJFc"
      },
      "cell_type": "code",
      "source": [
        "# Reshape input data from (28,28) to (28, 28, 1), to 3D\n",
        "# height x width x channel. we have gray scale images so channel = 1\n",
        "print(np.shape(x_test))\n",
        "w, h = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
        "print(np.shape(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WtMTwCY4l_Fb"
      },
      "cell_type": "markdown",
      "source": [
        "# **Build the CNN model**\n",
        "- Make sure to define the input shape in the first layer of the neural network. \n",
        "- The rest of the layers can adjust the input and output shapes automatically\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "![picture](https://nasirml.files.wordpress.com/2019/01/simple_convnet-3.png?w=580&h=182)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   Convolutional layer (conv):\n",
        "*   ReLU layer:\n",
        "*   Pooling layer:\n",
        "*   Dropout layer:\n",
        "*   Fully connected layer (FC):\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SnFu06Sb2aMy"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "* We use `model.compile()`  to configure the learning process before training the model. \n",
        "\n",
        "* This is where we define the type of loss function, optimizer and the metrics evaluated by the model during training and testing.\n",
        "\n",
        "* **Important:** before we apply the fully-connected layers, we need to flatten the the current output."
      ]
    },
    {
      "metadata": {
        "id": "HehPCCVlRTPg"
      },
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential()\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1))) \n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(256, activation='relu')) # 1568*256+256 = 401664 params total\n",
        "  model.add(tf.keras.layers.Dropout(0.5))\n",
        "  model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OhOSdfU3mKX"
      },
      "cell_type": "code",
      "source": [
        "# create the model \n",
        "\n",
        "model = create_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8MO8gcnh3t7J"
      },
      "cell_type": "markdown",
      "source": [
        "## **Model summary**\n",
        "\n",
        "* `conv2d` means the convolution in 2D (using 3x3 filters).\n",
        "* Number of parameters 640 comes from `3*3*64 + 64`\n"
      ]
    },
    {
      "metadata": {
        "id": "sW0ommccqqWH"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Take a look at the model summary\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7Z1KlFjtmYFV"
      },
      "cell_type": "markdown",
      "source": [
        "# **Now Train our model CNN**\n",
        "\n",
        "\n",
        "\n",
        "*  Train the model and also save the checkpoint so that we do not have to train everytime\n",
        "\n",
        "*   Shuffle is TRUE by default. Still I include it to tell that this is very important.\n",
        "\n",
        "*  Takes around 20 minutes for 10 epochs/iterations.\n",
        "\n",
        "* Loss decreases and accuracy increases\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3xIscEpWTj2v"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "- more params\n",
        "  - validation_split=0.1 means 10% of the training data will be used for validation set\n",
        "  -\n",
        "'''\n",
        "n_iteration = 10\n",
        "history = model.fit(x_train, y_train, batch_size=64, epochs=n_iteration, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ATHIdDHmgnI"
      },
      "cell_type": "markdown",
      "source": [
        "# **See how the training has gone**\n",
        "\n",
        "* Lets evaluate our model on the test set.\n",
        "* Looks like our CNN model doing a pretty good job at classifying the unknown images with almost 90% accuracy with 3 iterations and  and 92% with 10 epochs!"
      ]
    },
    {
      "metadata": {
        "id": "6niufMP8VpGr"
      },
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy: %f' %test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pr9wbLPU-nZG"
      },
      "cell_type": "markdown",
      "source": [
        "## **See the loss**\n",
        "\n",
        "* Loss should decrease over time.\n",
        "* If you see that the loss in your program does not decrease over time, most likely, something went wrong and you should check with your input and network initialization and hyper-parameters.\n"
      ]
    },
    {
      "metadata": {
        "id": "S3xIa-n2mkIi"
      },
      "cell_type": "code",
      "source": [
        "# history. all losses\n",
        "all_loss = history.history['loss']\n",
        "print(len(all_loss))\n",
        "\n",
        "# show the training errors\n",
        "plt.plot(np.squeeze(all_loss))\n",
        "plt.xlabel('iterations');plt.ylabel('cost')\n",
        "#plt.title('Learning rate %f' %learning_rate)\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w4ijZQNhX_2x"
      },
      "cell_type": "markdown",
      "source": [
        "## **Visualize some predictions**\n",
        "\n",
        "* Let's randomly pick some **test** images and visualize the prediction using the model we just trained. First we get the predictions with the model from the test data. Then we print out some images from the test data set, and set the titles with the prediction (and the groud truth label). If the prediction matches the true label, the title will be green; otherwise it's displayed in red.\n",
        "\n",
        "* As we know the accuracy is around 90%, we see that the network occasionaly makes mistakes to predict a class.\n",
        "\n",
        "* You can convince yourself that the mistakes are somewhat reasonable."
      ]
    },
    {
      "metadata": {
        "id": "vRQwa3x9X-0_"
      },
      "cell_type": "code",
      "source": [
        "# find the probability of the 10 classes and then assign the class label with \n",
        "# the higher probability.  model.predict(x_test) gives directly the probabilities\n",
        "# predicted for each of the class labels.\n",
        "y_hat = model.predict(x_test)\n",
        "print(y_hat.shape)\n",
        "print (y_hat[500])\n",
        "print (np.round(y_hat[500],2))\n",
        "\n",
        "# Plot a random sample of 16 test images, their predicted labels and ground truth\n",
        "figure = plt.figure(figsize=(20, 8))\n",
        "for i, index in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
        "    ax = figure.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
        "    # Display each image\n",
        "    ax.imshow(np.squeeze(x_test[index]),cmap='gray')\n",
        "    predict_index = np.argmax(y_hat[index])                 # The fashion label number that is predicted \n",
        "    true_index = np.argmax(y_test[index])                   # The true label number\n",
        "    # Set the title for each image\n",
        "    ax.set_title(\"{} ({})\".format(fashion_mnist_labels[predict_index], \n",
        "                                  fashion_mnist_labels[true_index]),\n",
        "                                  color=(\"green\" if predict_index == true_index else \"red\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVckTdfkfeYD"
      },
      "cell_type": "markdown",
      "source": [
        "## **TODO**\n",
        "\n",
        "\n",
        "1. **Add one convolution layer** in the network and train again. See if it increases the accuracy. Optional: You could further try changing other aspects of the network archirecture and computations to see if you can improve the result.\n",
        "\n",
        "\n",
        "2. Find the **Confusion Matrix** and see how many samples in each class the network can predict correctly and how many are not predicted correctly. To do so, create a 10 by 10 matrix initialized to zeros, with the X axis corresponding to the true index and the Y axis to the predicted index. Loop over the 10,000 samples and each time add 1 to the matrix position asscoiated with the true index on the X axis and predicted index on the Y axis. Use plt.imshow to display your resulting matrix. What fashion items are most confused? What would the confusion matrix look like for a perfect network that always predicts correctly?\n",
        "\n",
        "3. Try training the regular mnist database (replace fashion_mnist with mnist). How do the test accuracy and confusion matrices compare to the fashion_mnist?\n",
        "\n",
        "\n"
      ]
    }
  ]
}
