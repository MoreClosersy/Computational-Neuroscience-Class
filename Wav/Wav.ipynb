{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCO1SQU7CiZUuXvi/b+aRq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xup5/Computational-Neuroscience-Class/blob/main/Wav/Wav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wave\n",
        "\n",
        "This is a tutorial and exercises for sound statistics and linear mixing.\n",
        "\n",
        "Odelia Schwartz, Computational Neuroscience course, 2017.\n",
        "Code with Luis Gonzalo Sanchez Giraldo. Transcribed and modified by Xu Pan in 2022."
      ],
      "metadata": {
        "id": "A0DqeRozAxtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Linear mixing of sounds\n",
        "\n",
        "Linear mixing of sounds and cocktail party effect.\n",
        "Introduction to looking at the statistics."
      ],
      "metadata": {
        "id": "ze0pulSVBMpE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQHMLqz0Ae1u"
      },
      "outputs": [],
      "source": [
        "# download .wav files from our repository\n",
        "\n",
        "!wget https://github.com/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Wav/spa.wav?raw=true -O spa.wav\n",
        "!wget https://github.com/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Wav/spc.wav?raw=true -O spc.wav\n",
        "!wget https://github.com/schwartz-cnl/Computational-Neuroscience-Class/blob/main/Wav/spd.wav?raw=true -O spd.wav"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read speech sounds\n",
        "\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "\n",
        "sample_rate_1, y1 = wavfile.read('spd.wav')\n",
        "sample_rate_2, y2 = wavfile.read('spc.wav')"
      ],
      "metadata": {
        "id": "TZMdClOgBuj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take numsamps samples of each sound\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "numsamps = 40000\n",
        "y1=y1[0:numsamps]\n",
        "y2=y2[0:numsamps]\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(y1, y2, facecolor='g', s=1)\n",
        "tmp = np.max(np.abs([y1,y2]))\n",
        "plt.axis([-tmp, tmp, -tmp, tmp])\n",
        "plt.title('Original Sources', fontsize=16)\n",
        "plt.xlabel('y1', fontsize=16)\n",
        "plt.ylabel('y2', fontsize=16)"
      ],
      "metadata": {
        "id": "nxo60WoFCGqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to the sounds\n",
        "\n",
        "import IPython.display as ipd\n",
        "\n",
        "ipd.display(ipd.Audio(y1, rate=sample_rate_1))\n",
        "ipd.display(ipd.Audio(y2, rate=sample_rate_2))"
      ],
      "metadata": {
        "id": "nVcl1TTcF1LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Linear mix the sounds\n",
        "# Create y3 that linearly mixes y1 and y2 in proportion mix1 and (1-mix1) and\n",
        "# y4 that linearly mixes y1 and y2 in proportion mix2 and (1-mix2). Set mix1 \n",
        "# to 0.6 and mix2 to 0.4\n",
        "\n",
        "mix1 = \n",
        "mix2 = \n",
        "y3 = \n",
        "y4 = \n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(y3, y4, s=1)\n",
        "tmp = np.max(np.abs([y3,y4]))\n",
        "plt.axis([-tmp, tmp, -tmp, tmp])\n",
        "plt.title('Observed mixtures', fontsize=16)\n",
        "plt.xlabel('mix1', fontsize=16)\n",
        "plt.ylabel('mix2', fontsize=16)"
      ],
      "metadata": {
        "id": "9UgxxHHXKZBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to the mixed sounds\n",
        "\n",
        "ipd.display(ipd.Audio(y3, rate=sample_rate_1))\n",
        "ipd.display(ipd.Audio(y4, rate=sample_rate_1))"
      ],
      "metadata": {
        "id": "vhtmPKM_K4eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA"
      ],
      "metadata": {
        "id": "qLVtNMiPPPKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try PCA (from sklearn package). Does it work in separating the sounds? Why?\n",
        "# Plot a scatter plot of the PCA components.\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "principalComponents = pca.fit_transform(np.array([y3,y4]).T)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(principalComponents[:,0], principalComponents[:,1], s=1)\n",
        "tmp = np.max(np.abs(principalComponents))\n",
        "plt.axis([-tmp, tmp, -tmp, tmp])\n",
        "plt.title('Decorelated mixtures', fontsize=16)\n",
        "plt.xlabel('pca1', fontsize=16)\n",
        "plt.ylabel('pca2', fontsize=16)"
      ],
      "metadata": {
        "id": "cXW4ZGTMLGZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to the PCA sounds.\n",
        "\n",
        "ipd.display(ipd.Audio(principalComponents[:,0], rate=sample_rate_1))\n",
        "ipd.display(ipd.Audio(principalComponents[:,1], rate=sample_rate_1))"
      ],
      "metadata": {
        "id": "8wIc4nlTNQY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ICA"
      ],
      "metadata": {
        "id": "ypqiGDYtPR0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try ICA. Does it work in separating the sounds? Why?\n",
        "\n",
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "ica = FastICA(n_components=2)\n",
        "ICAComponents = ica.fit_transform(np.array([y3,y4]).T)\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.scatter(ICAComponents[:,0], ICAComponents[:,1], s=1)\n",
        "tmp = np.max(np.abs(ICAComponents))\n",
        "plt.axis([-tmp, tmp, -tmp, tmp])\n",
        "plt.title('Independent mixtures', fontsize=16)\n",
        "plt.xlabel('pca1', fontsize=16)\n",
        "plt.ylabel('pca2', fontsize=16)"
      ],
      "metadata": {
        "id": "PfF90N5dOR9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Listen to the ICA sounds\n",
        "\n",
        "ipd.display(ipd.Audio(ICAComponents[:,0], rate=sample_rate_1))\n",
        "ipd.display(ipd.Audio(ICAComponents[:,1], rate=sample_rate_1))"
      ],
      "metadata": {
        "id": "lfYxqIa4Osj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sound statistics"
      ],
      "metadata": {
        "id": "NQNeE96fPUxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Look at the statistics of the sounds\n",
        "\n",
        "from scipy.stats import kurtosis\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, constrained_layout=True, figsize=(8, 4))\n",
        "\n",
        "axs[0].hist(y1, bins=200)\n",
        "axs[0].set_title('y1 distribution', fontsize=16);\n",
        "\n",
        "axs[1].hist(y2, bins=200)\n",
        "axs[1].set_title('y2 distribution', fontsize=16);\n",
        "\n",
        "print('y1 kurtosis: {}, y2 kurtosis: {}'.format(kurtosis(y1),kurtosis(y2)))"
      ],
      "metadata": {
        "id": "Oo22g_PYPLLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Questions & TO DO:\n",
        "1) Plot y1, y2, y3, and y4\n",
        "\n",
        "2) Did PCA work in separating the mixed speech sounds? Why or why not?\n",
        "\n",
        "3) Did ICA work in separating the mixed speech sounds? Why or why not?\n",
        "\n",
        "4) Try other values of mix1 and mix2 (larger than 0 and smaller than 1). Are there values for which the unmixing fails?\n",
        "\n",
        "5) Compare the speech sound statistics we observed for y1 to a Gaussian. Use np.random.randn to generate a Gaussian named thegauss the same length of y1. Plot the histogram, and find the kurtosis. How do the speech signals compare to a Gaussian?\n",
        "\n",
        "6) You can also compute the kurtosis of the pca and ica signals."
      ],
      "metadata": {
        "id": "7q6j1YaDTHxz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "imVCnBf_TL1H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
